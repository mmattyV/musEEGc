{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne import pick_types\n",
    "from mne.io import read_raw_eeglab\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import torch\n",
    "import multiprocessing\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "\n",
    "num_sub = 20\n",
    "num_sess = 12\n",
    "use_gpu = 0\n",
    "use_mps = 1\n",
    "cuda_device = 0\n",
    "train_dir = '../prepro_data/train'\n",
    "val_dir = '../prepro_data/val'\n",
    "train_behav_file = 'train_behav.csv'\n",
    "val_behav_file = 'val_behav.csv'\n",
    "base_lr = 0.0001\n",
    "decay_weight = 0.1 \n",
    "epoch_decay = 5 \n",
    "b_size = 3\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "create_dir(train_dir)\n",
    "create_dir(val_dir)\n",
    "\n",
    "for i in range(1, num_sub+1):\n",
    "    for j in range(1, num_sess+1):\n",
    "        data_path = f'../ds003774/sub-0{i//10}{i%10}/ses-{j//10}{j%10}/eeg/sub-0{i//10}{i%10}_ses-{j//10}{j%10}_task-MusicListening_run-{j}_eeg.set'\n",
    "        raw = read_raw_eeglab(data_path, preload=True)\n",
    "\n",
    "        # High-pass filter at 0.2 Hz\n",
    "        raw.filter(l_freq=0.2, h_freq=None)\n",
    "\n",
    "        # Remove 50 Hz line noise\n",
    "        raw.notch_filter(freqs=[50])\n",
    "\n",
    "        # Downsample the data to 256 Hz\n",
    "        raw.resample(256)\n",
    "\n",
    "        # Extract EEG data and calculate PSD using Welch's method\n",
    "        picks = pick_types(raw.info, eeg=True, exclude=[])\n",
    "        data, times = raw.get_data(picks=picks, return_times=True)\n",
    "        psds, freqs = psd_array_welch(data, sfreq=raw.info['sfreq'], fmin=2, fmax=40)\n",
    "\n",
    "        # Calculate the mean and threshold for PSD\n",
    "        psd_mean = psds.mean(axis=-1)\n",
    "        psd_threshold = 3 * np.std(psds, axis=-1)  # Calculate the standard deviation along the frequency axis\n",
    "\n",
    "        # Identify bad channels based on spectral criteria\n",
    "        bad_channels = [raw.ch_names[p] for p in picks if psd_mean[p] > psd_threshold[p]]\n",
    "        raw.info['bads'] += bad_channels\n",
    "        raw.interpolate_bads()\n",
    "\n",
    "        # Artifact rejection using ICA\n",
    "        ica = ICA(n_components=20, random_state=99, method='fastica')\n",
    "        ica.fit(raw)\n",
    "        ica.apply(raw)\n",
    "\n",
    "        # Re-reference the data to the average\n",
    "        raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "        # Save preprocessed data\n",
    "        pre_path = f'pre_eeg_sub-0{i//10}{i%10}_ses-{j//10}{j%10}_eeg.fif'\n",
    "        if i <= 16:\n",
    "            pre_path = os.path.join(train_dir, pre_path)\n",
    "        else:\n",
    "            pre_path = os.path.join(val_dir, pre_path)\n",
    "        raw.save(pre_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class for the V vs. Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset(Dataset):\n",
    "    # Bin and hot encode our labels for our targets\n",
    "    # Bins: [high familiarity & high enjoyment, \n",
    "    #        high familiarity & low enjoyment, \n",
    "    #        low familiarity & high enjoyment, \n",
    "    #        low familiarity & low enjoyment]\n",
    "    # High is >= 2.5\n",
    "    # Low is < 2.5\n",
    "    def get_target(self, row):\n",
    "        # HEHF\n",
    "        if row[2] >= 2.5 and row[3] >= 2.5:\n",
    "            return 0, 'HEHF'\n",
    "        # HELF\n",
    "        elif row[2] >= 2.5 and row[3] < 2.5:\n",
    "            return 1, 'HELF'\n",
    "        # LEHF\n",
    "        elif row[2] < 2.5 and row[3] >= 2.5:\n",
    "            return 2, 'LEHF'\n",
    "        # LELF\n",
    "        else:\n",
    "            return 3, 'LELF'\n",
    "        \n",
    "    def __init__(self, data_dir, behav_file, transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.behav_file = behav_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data_dict = {}\n",
    "\n",
    "        eeg_label_dict = {}\n",
    "        self.class_counts = {}\n",
    "\n",
    "        tags = ['HEHF', 'HELF', 'LEHF', 'LELF']\n",
    "        \n",
    "        for tag in tags:\n",
    "            self.class_counts[tag] = 0\n",
    "\n",
    "        df = pd.read_csv(self.behav_file)\n",
    "        behav_data = df.values\n",
    "\n",
    "        total_files = 0\n",
    "        for entry in os.listdir(self.data_dir):\n",
    "            # Join the directory path with the entry name to get full file path\n",
    "            full_path = os.path.join(self.data_dir, entry)\n",
    "            if os.path.isfile(full_path):\n",
    "                total_files += 1\n",
    "    \n",
    "        progress_bar = tqdm(total=len(behav_data))\n",
    "\n",
    "        id = 0\n",
    "        for row in behav_data:\n",
    "            existing_files = set(os.listdir(self.data_dir))\n",
    "\n",
    "            data_path = f'pre_eeg_sub-0{row[0]//10}{row[0]%10}_ses-{row[1]//10}{row[1]%10}_eeg.fif'\n",
    "            if data_path in existing_files:\n",
    "                data_path = os.path.join(self.data_dir, data_path)\n",
    "                full_data = mne.io.read_raw_fif(data_path, preload=False)\n",
    "\n",
    "                # Splitting full EEG recording into 5 second slices\n",
    "                num_intervals = full_data.get_data().shape[1] // 1250\n",
    "                for i in range(num_intervals):\n",
    "                    slice = [data_path, i*1250, i*1250+1250]\n",
    "                    \n",
    "                    target, tag_string = self.get_target(row)\n",
    "\n",
    "                    self.data_dict[id] = slice\n",
    "\n",
    "                    eeg_label_dict[id] = target\n",
    "                    self.class_counts[tag_string] += 1\n",
    "                    id += 1\n",
    "\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        progress_bar.close()\n",
    "\n",
    "        self.items = list(eeg_label_dict.items())\n",
    "        print('Class counts: ', self.class_counts)\n",
    "\n",
    "    def get_class_counts(self):\n",
    "        enum_class_count = {}\n",
    "        i = 0\n",
    "        for _, count in self.class_counts.items():\n",
    "            enum_class_count[i] = count\n",
    "            i += 1\n",
    "        return enum_class_count\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        return self.items[idx][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.items[idx][1]\n",
    "        eeg_index = self.data_dict[self.items[idx][0]]\n",
    "\n",
    "        full_data = mne.io.read_raw_fif(eeg_index[0], preload=False)\n",
    "        eeg_data = full_data.get_data()[:, eeg_index[1] : eeg_index[2]]\n",
    "\n",
    "        if self.transform:\n",
    "            eeg_data = self.transform(eeg_data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return eeg_data[0], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "\n",
    "if use_mps:\n",
    "   mps_device = torch.device(\"mps\")\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=base_lr, lr_decay_epoch=epoch_decay):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (decay_weight**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for the V vs. Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EEGCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 40), padding=(1, 20))  # Preserves time dimension\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 25), padding=(1, 12))  # Preserves time dimension\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 10), padding=(1, 5))  # Preserves time dimension\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d((2, 4))  # Reduces height by 2, width by 4\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Calculating the output dimensions after pooling:\n",
    "        # Initial input shape: (1, 129, 1250)\n",
    "        # After first pool: (16, 65, 312)\n",
    "        # After second pool: (32, 33, 78)\n",
    "        # After third pool: (64, 17, 20)\n",
    "        self.fc1 = nn.Linear(19456, 100)  # 64 channels, height 17, width 20\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "    losses = {'train': [], 'val': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            counter = 0\n",
    "\n",
    "            \n",
    "            for data in dset_loaders[phase]:\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    try:\n",
    "                        inputs, labels = Variable(inputs.float().cuda()), Variable(labels.long().cuda())\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(\"ERROR! here are the inputs and labels before we print the full stack trace:\")\n",
    "                        print(inputs, labels)\n",
    "                        raise e\n",
    "                    \n",
    "                elif use_mps:\n",
    "                   try:\n",
    "                      inputs, labels = Variable(inputs.float().to(mps_device)), Variable(labels.long().to(mps_device))\n",
    "\n",
    "                   except Exception as e:\n",
    "                      print(\"ERROR! here are the inputs and labels before we print the full stack trace:\")\n",
    "                      print(inputs, labels)\n",
    "                      raise e\n",
    "                \n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                print(counter)\n",
    "                \n",
    "                if counter%100 == 0:\n",
    "                    print('Reached batch iteration', counter)\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                try:\n",
    "                    running_loss += loss.item()\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                except:\n",
    "                    print('unexpected error, could not calculate loss or do a sum.')\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects.item() / float(dset_sizes[phase])\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    print('new best accuracy =', best_acc)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('returning and looping back')\n",
    "\n",
    "    return best_model, accuracies, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop for CNN & V vs. Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {}\n",
    "dsets['train'] = RawDataset(train_dir, train_behav_file, data_transforms['train'])\n",
    "dsets['val'] = RawDataset(val_dir, val_behav_file, data_transforms['val'])\n",
    "\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    targets = np.zeros(dsets[split].__len__())\n",
    "    for i in range(len(targets)):\n",
    "        label = dsets[split].get_label(i)\n",
    "        targets[i] = label\n",
    "    class_counts = dsets[split].get_class_counts()\n",
    "    class_weights = {tag: 1.0 / count if count > 0 else 0 for tag, count in class_counts.items()}\n",
    "    weights = np.array([class_weights[tag] for tag in targets])\n",
    "    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=b_size, num_workers=0, sampler=sampler)\n",
    "    print('done making loader: ', split)\n",
    "model_ft = EEGCNN(num_classes=4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if use_gpu:\n",
    "    criterion.cuda()\n",
    "    model_ft.cuda()\n",
    "\n",
    "if use_mps:\n",
    "    criterion.to(mps_device)\n",
    "    model_ft.to(mps_device)\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=n_epochs)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    print(split, 'accuracies by epoch:', accuracies[split])\n",
    "    print(split, 'losses by epoch:', losses[split])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class for spectrogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectroDataset(Dataset):\n",
    "    # Bin and hot encode our labels for our targets\n",
    "    # Bins: [high familiarity & high enjoyment, \n",
    "    #        high familiarity & low enjoyment, \n",
    "    #        low familiarity & high enjoyment, \n",
    "    #        low familiarity & low enjoyment]\n",
    "    # High is >= 2.5\n",
    "    # Low is < 2.5\n",
    "    def get_target(self, row):\n",
    "        # HEHF\n",
    "        if row[2] >= 2.5 and row[3] >= 2.5:\n",
    "            return 0, 'HEHF'\n",
    "        # HELF\n",
    "        elif row[2] >= 2.5 and row[3] < 2.5:\n",
    "            return 1, 'HELF'\n",
    "        # LEHF\n",
    "        elif row[2] < 2.5 and row[3] >= 2.5:\n",
    "            return 2, 'LEHF'\n",
    "        # LELF\n",
    "        else:\n",
    "            return 3, 'LELF'\n",
    "        \n",
    "    def __init__(self, data_dir, behav_file, transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.behav_file = behav_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data_dict = {}\n",
    "\n",
    "        eeg_label_dict = {}\n",
    "        self.class_counts = {}\n",
    "\n",
    "        tags = ['HEHF', 'HELF', 'LEHF', 'LELF']\n",
    "        \n",
    "        for tag in tags:\n",
    "            self.class_counts[tag] = 0\n",
    "\n",
    "        df = pd.read_csv(self.behav_file)\n",
    "        behav_data = df.values\n",
    "\n",
    "        total_files = 0\n",
    "        for entry in os.listdir(self.data_dir):\n",
    "            # Join the directory path with the entry name to get full file path\n",
    "            full_path = os.path.join(self.data_dir, entry)\n",
    "            if os.path.isfile(full_path):\n",
    "                total_files += 1\n",
    "    \n",
    "        progress_bar = tqdm(total=len(behav_data))\n",
    "\n",
    "        id = 0\n",
    "        for row in behav_data:\n",
    "            existing_files = set(os.listdir(self.data_dir))\n",
    "\n",
    "            data_path = f'pre_eeg_sub-0{row[0]//10}{row[0]%10}_ses-{row[1]//10}{row[1]%10}_eeg.fif'\n",
    "            if data_path in existing_files:\n",
    "                data_path = os.path.join(self.data_dir, data_path)\n",
    "                full_data = mne.io.read_raw_fif(data_path, preload=False)\n",
    "\n",
    "                # Splitting full EEG recording into 5 second slices\n",
    "                num_intervals = (full_data.get_data().shape[1] // 3) // (84 * 5)\n",
    "                for i in range(num_intervals):\n",
    "                    slice = [data_path, i*84, i*84+84]\n",
    "                    \n",
    "                    target, tag_string = self.get_target(row)\n",
    "\n",
    "                    self.data_dict[id] = slice\n",
    "\n",
    "                    eeg_label_dict[id] = target\n",
    "                    self.class_counts[tag_string] += 1\n",
    "                    id += 1\n",
    "\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        progress_bar.close()\n",
    "\n",
    "        self.items = list(eeg_label_dict.items())\n",
    "        print('Class counts: ', self.class_counts)\n",
    "\n",
    "    def get_class_counts(self):\n",
    "        enum_class_count = {}\n",
    "        i = 0\n",
    "        for _, count in self.class_counts.items():\n",
    "            enum_class_count[i] = count\n",
    "            i += 1\n",
    "        return enum_class_count\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        return self.items[idx][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.items[idx][1]\n",
    "        eeg_index = self.data_dict[self.items[idx][0]]\n",
    "\n",
    "        full_data = mne.io.read_raw_fif(eeg_index[0], preload=False)\n",
    "        # Define frequencies of interest (log-spaced)\n",
    "        frequencies = np.logspace(np.log10(1), np.log10(40), num=40)\n",
    "        n_cycles = frequencies / 2.  # Different number of cycle per frequency\n",
    "        # Compute time-frequency representation with Morlet wavelets\n",
    "        power = tfr_morlet(full_data, freqs=frequencies, n_cycles=n_cycles, use_fft=True, return_itc=False, decim=3, n_jobs=1)\n",
    "        # power has shape (129, 40, 11609)\n",
    "\n",
    "        eeg_data = power.get_data()[:, :, eeg_index[1] : eeg_index[2]]\n",
    "\n",
    "        if self.transform:\n",
    "            eeg_data = self.transform(eeg_data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        new_shape = (eeg_data.shape[0], eeg_data.shape[1] * eeg_data.shape[2])  # (129, 40*84)\n",
    "        eeg_data = eeg_data.reshape(new_shape)\n",
    "\n",
    "        return eeg_data, label\n",
    "        # eeg_data has shape (129, 3360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SpectrogramCNN, self).__init__()\n",
    "        # Reduce the number of convolutional layers and channels\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 10), padding=(1, 5))  # One layer, more channels\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d((2, 4))  # Pooling to reduce dimensions\n",
    "\n",
    "        # Simplified dropout and fewer fully connected layers\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        # The fully connected layer sizes need to be adjusted based on the actual output dimensions\n",
    "        # Placeholder dimensions for illustration; you will need to calculate the exact number based on your input size after pooling\n",
    "        self.fc1 = nn.Linear(1733760, num_classes)  # Direct connection to output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop for CNN & spectrogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:10<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:  {'HEHF': 2482, 'HELF': 238, 'LEHF': 1366, 'LELF': 874}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:  {'HEHF': 507, 'HELF': 100, 'LEHF': 533, 'LELF': 100}\n",
      "done making loader:  train\n",
      "done making loader:  val\n",
      "----------\n",
      "Epoch 0/9\n",
      "----------\n",
      "LR is set to 0.0001\n",
      "0\n",
      "Reached batch iteration 0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dsets = {}\n",
    "dsets['train'] = SpectroDataset(train_dir, train_behav_file, data_transforms['train'])\n",
    "dsets['val'] = SpectroDataset(val_dir, val_behav_file, data_transforms['val'])\n",
    "\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    targets = np.zeros(dsets[split].__len__())\n",
    "    for i in range(len(targets)):\n",
    "        label = dsets[split].get_label(i)\n",
    "        targets[i] = label\n",
    "    class_counts = dsets[split].get_class_counts()\n",
    "    class_weights = {tag: 1.0 / count if count > 0 else 0 for tag, count in class_counts.items()}\n",
    "    weights = np.array([class_weights[tag] for tag in targets])\n",
    "    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=b_size, num_workers=0, sampler=sampler)\n",
    "    print('done making loader: ', split)\n",
    "model_ft = SpectrogramCNN(num_classes=4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if use_gpu:\n",
    "    criterion.cuda()\n",
    "    model_ft.cuda()\n",
    "\n",
    "if use_mps:\n",
    "    criterion.to(mps_device)\n",
    "    model_ft.to(mps_device)\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=n_epochs)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    print(split, 'accuracies by epoch:', accuracies[split])\n",
    "    print(split, 'losses by epoch:', losses[split])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
