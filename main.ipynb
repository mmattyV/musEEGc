{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne import pick_types\n",
    "from mne.io import read_raw_eeglab\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import torch\n",
    "import multiprocessing\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "\n",
    "num_sub = 20\n",
    "num_sess = 12\n",
    "cuda_device = 0\n",
    "train_dir = '../prepro_data/train'\n",
    "val_dir = '../prepro_data/val'\n",
    "train_behav_file = 'train_behav.csv'\n",
    "val_behav_file = 'val_behav.csv'\n",
    "base_lr = 0.0001\n",
    "decay_weight = 0.1 \n",
    "epoch_decay = 5 \n",
    "b_size = 5\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "create_dir(train_dir)\n",
    "create_dir(val_dir)\n",
    "\n",
    "for i in range(1, num_sub+1):\n",
    "    for j in range(1, num_sess+1):\n",
    "        data_path = f'../ds003774/sub-0{i//10}{i%10}/ses-{j//10}{j%10}/eeg/sub-0{i//10}{i%10}_ses-{j//10}{j%10}_task-MusicListening_run-{j}_eeg.set'\n",
    "        raw = read_raw_eeglab(data_path, preload=True)\n",
    "\n",
    "        # High-pass filter at 0.2 Hz\n",
    "        raw.filter(l_freq=0.2, h_freq=None)\n",
    "\n",
    "        # Remove 50 Hz line noise\n",
    "        raw.notch_filter(freqs=[50])\n",
    "\n",
    "        # Downsample the data to 256 Hz\n",
    "        raw.resample(256)\n",
    "\n",
    "        # Extract EEG data and calculate PSD using Welch's method\n",
    "        picks = pick_types(raw.info, eeg=True, exclude=[])\n",
    "        data, times = raw.get_data(picks=picks, return_times=True)\n",
    "        psds, freqs = psd_array_welch(data, sfreq=raw.info['sfreq'], fmin=2, fmax=40)\n",
    "\n",
    "        # Calculate the mean and threshold for PSD\n",
    "        psd_mean = psds.mean(axis=-1)\n",
    "        psd_threshold = 3 * np.std(psds, axis=-1)  # Calculate the standard deviation along the frequency axis\n",
    "\n",
    "        # Identify bad channels based on spectral criteria\n",
    "        bad_channels = [raw.ch_names[p] for p in picks if psd_mean[p] > psd_threshold[p]]\n",
    "        raw.info['bads'] += bad_channels\n",
    "        raw.interpolate_bads()\n",
    "\n",
    "        # Artifact rejection using ICA\n",
    "        ica = ICA(n_components=20, random_state=99, method='fastica')\n",
    "        ica.fit(raw)\n",
    "        ica.apply(raw)\n",
    "\n",
    "        # Re-reference the data to the average\n",
    "        raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "        # Save preprocessed data\n",
    "        pre_path = f'pre_eeg_sub-0{i//10}{i%10}_ses-{j//10}{j%10}_eeg.fif'\n",
    "        if i <= 16:\n",
    "            pre_path = os.path.join(train_dir, pre_path)\n",
    "        else:\n",
    "            pre_path = os.path.join(val_dir, pre_path)\n",
    "        raw.save(pre_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class for the V vs. Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset(Dataset):\n",
    "    # Bin and hot encode our labels for our targets\n",
    "    # Bins: [high familiarity & high enjoyment, \n",
    "    #        high familiarity & low enjoyment, \n",
    "    #        low familiarity & high enjoyment, \n",
    "    #        low familiarity & low enjoyment]\n",
    "    # High is >= 2.5\n",
    "    # Low is < 2.5\n",
    "    def get_target(self, row):\n",
    "        # HEHF\n",
    "        if row[2] >= 2.5 and row[3] >= 2.5:\n",
    "            return 0, 'HEHF'\n",
    "        # HELF\n",
    "        elif row[2] >= 2.5 and row[3] < 2.5:\n",
    "            return 1, 'HELF'\n",
    "        # LEHF\n",
    "        elif row[2] < 2.5 and row[3] >= 2.5:\n",
    "            return 2, 'LEHF'\n",
    "        # LELF\n",
    "        else:\n",
    "            return 3, 'LELF'\n",
    "        \n",
    "    def __init__(self, data_dir, behav_file, transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.behav_file = behav_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data_dict = {}\n",
    "\n",
    "        eeg_label_dict = {}\n",
    "        self.class_counts = {}\n",
    "\n",
    "        tags = ['HEHF', 'HELF', 'LEHF', 'LELF']\n",
    "        \n",
    "        for tag in tags:\n",
    "            self.class_counts[tag] = 0\n",
    "\n",
    "        df = pd.read_csv(self.behav_file)\n",
    "        behav_data = df.values\n",
    "\n",
    "        total_files = 0\n",
    "        for entry in os.listdir(self.data_dir):\n",
    "            # Join the directory path with the entry name to get full file path\n",
    "            full_path = os.path.join(self.data_dir, entry)\n",
    "            if os.path.isfile(full_path):\n",
    "                total_files += 1\n",
    "    \n",
    "        progress_bar = tqdm(total=len(behav_data))\n",
    "\n",
    "        id = 0\n",
    "        for row in behav_data:\n",
    "            existing_files = set(os.listdir(self.data_dir))\n",
    "\n",
    "            data_path = f'pre_eeg_sub-0{row[0]//10}{row[0]%10}_ses-{row[1]//10}{row[1]%10}_eeg.fif'\n",
    "            if data_path in existing_files:\n",
    "                data_path = os.path.join(self.data_dir, data_path)\n",
    "                full_data = mne.io.read_raw_fif(data_path, preload=False)\n",
    "\n",
    "                # Splitting full EEG recording into 5 second slices\n",
    "                num_intervals = full_data.get_data().shape[1] // 1250\n",
    "                for i in range(num_intervals):\n",
    "                    slice = [data_path, i*1250, i*1250+1250]\n",
    "                    \n",
    "                    target, tag_string = self.get_target(row)\n",
    "\n",
    "                    self.data_dict[id] = slice\n",
    "\n",
    "                    eeg_label_dict[id] = target\n",
    "                    self.class_counts[tag_string] += 1\n",
    "                    id += 1\n",
    "\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        progress_bar.close()\n",
    "\n",
    "        self.items = list(eeg_label_dict.items())\n",
    "        print('Class counts: ', self.class_counts)\n",
    "\n",
    "    def get_class_counts(self):\n",
    "        enum_class_count = {}\n",
    "        i = 0\n",
    "        for _, count in self.class_counts.items():\n",
    "            enum_class_count[i] = count\n",
    "            i += 1\n",
    "        return enum_class_count\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        return self.items[idx][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.items[idx][1]\n",
    "        eeg_index = self.data_dict[self.items[idx][0]]\n",
    "\n",
    "        full_data = mne.io.read_raw_fif(eeg_index[0], preload=False)\n",
    "        eeg_data = full_data.get_data()[:, eeg_index[1] : eeg_index[2]]\n",
    "\n",
    "        if self.transform:\n",
    "            eeg_data = self.transform(eeg_data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return eeg_data[0], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "elif torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=base_lr, lr_decay_epoch=epoch_decay):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (decay_weight**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for the V vs. Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EEGCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 40), padding=(1, 20))  # Preserves time dimension\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 25), padding=(1, 12))  # Preserves time dimension\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 10), padding=(1, 5))  # Preserves time dimension\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d((2, 4))  # Reduces height by 2, width by 4\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Calculating the output dimensions after pooling:\n",
    "        # Initial input shape: (1, 129, 1250)\n",
    "        # After first pool: (16, 65, 312)\n",
    "        # After second pool: (32, 33, 78)\n",
    "        # After third pool: (64, 17, 20)\n",
    "        self.fc1 = nn.Linear(19456, 100)  # 64 channels, height 17, width 20\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, dset_loaders, dset_sizes, num_epochs=10, device=None):\n",
    "    since = time.time()\n",
    "\n",
    "    if device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    \n",
    "    model.to(device)\n",
    "    print(\"Training on:\", device)\n",
    "\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "    losses = {'train': [], 'val': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            counter = 0\n",
    "\n",
    "            for inputs, labels in dset_loaders[phase]:\n",
    "                if counter%100 == 0:\n",
    "                    print('Reached batch iteration', counter)\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                #print('we are on batch', counter)\n",
    "\n",
    "                inputs = inputs.float().to(device)\n",
    "                labels = labels.long().to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dset_sizes[phase]\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print('New best accuracy = {:.4f}'.format(best_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    return best_model, accuracies, losses\n",
    "\n",
    "# Usage:\n",
    "# model, criterion, optimizer, and lr_scheduler need to be defined\n",
    "# dset_loaders should be a dictionary with 'train' and 'val' DataLoader objects\n",
    "# dset_sizes should be a dictionary with the sizes of these datasets\n",
    "# device can be set manually or will be set to CUDA if available, and MPS if on compatible macOS devices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop for CNN & V vs. Time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup datasets and loaders\n",
    "dsets = {\n",
    "    'train': RawDataset(train_dir, train_behav_file, data_transforms['train']),\n",
    "    'val': RawDataset(val_dir, val_behav_file, data_transforms['val'])\n",
    "}\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    targets = np.array([dsets[split].get_label(i) for i in range(len(dsets[split]))])\n",
    "    class_counts = dsets[split].get_class_counts()\n",
    "    class_weights = np.array([1.0 / class_counts[label] if class_counts[label] > 0 else 0 for label in targets])\n",
    "    sampler = WeightedRandomSampler(class_weights, num_samples=len(class_weights), replacement=True)\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=b_size, num_workers=0, sampler=sampler)\n",
    "    print('done making loader:', split)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model_ft = EEGCNN(num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "# Device configuration with MPS support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model_ft.to(device)\n",
    "criterion.to(device)\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Train model\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dset_loaders, dset_sizes, num_epochs=n_epochs)\n",
    "\n",
    "# Output results\n",
    "for split in ['train', 'val']:\n",
    "    print(split, 'accuracies by epoch:', accuracies[split])\n",
    "    print(split, 'losses by epoch:', losses[split])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class for spectrogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectroDataset(Dataset):\n",
    "    # Bin and hot encode our labels for our targets\n",
    "    # Bins: [high familiarity & high enjoyment, \n",
    "    #        high familiarity & low enjoyment, \n",
    "    #        low familiarity & high enjoyment, \n",
    "    #        low familiarity & low enjoyment]\n",
    "    # High is >= 2.5\n",
    "    # Low is < 2.5\n",
    "    def get_target(self, row):\n",
    "        # HEHF\n",
    "        if row[2] >= 2.5 and row[3] >= 2.5:\n",
    "            return 0, 'HEHF'\n",
    "        # HELF\n",
    "        elif row[2] >= 2.5 and row[3] < 2.5:\n",
    "            return 1, 'HELF'\n",
    "        # LEHF\n",
    "        elif row[2] < 2.5 and row[3] >= 2.5:\n",
    "            return 2, 'LEHF'\n",
    "        # LELF\n",
    "        else:\n",
    "            return 3, 'LELF'\n",
    "        \n",
    "    def __init__(self, data_dir, behav_file, transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.behav_file = behav_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data_dict = {}\n",
    "\n",
    "        eeg_label_dict = {}\n",
    "        self.class_counts = {}\n",
    "\n",
    "        tags = ['HEHF', 'HELF', 'LEHF', 'LELF']\n",
    "        \n",
    "        for tag in tags:\n",
    "            self.class_counts[tag] = 0\n",
    "\n",
    "        df = pd.read_csv(self.behav_file)\n",
    "        behav_data = df.values\n",
    "\n",
    "        total_files = 0\n",
    "        for entry in os.listdir(self.data_dir):\n",
    "            # Join the directory path with the entry name to get full file path\n",
    "            full_path = os.path.join(self.data_dir, entry)\n",
    "            if os.path.isfile(full_path):\n",
    "                total_files += 1\n",
    "    \n",
    "        progress_bar = tqdm(total=len(behav_data))\n",
    "\n",
    "        id = 0\n",
    "        for row in behav_data:\n",
    "            existing_files = set(os.listdir(self.data_dir))\n",
    "\n",
    "            data_path = f'pre_eeg_sub-0{row[0]//10}{row[0]%10}_ses-{row[1]//10}{row[1]%10}_eeg.fif'\n",
    "            if data_path in existing_files:\n",
    "                data_path = os.path.join(self.data_dir, data_path)\n",
    "                full_data = mne.io.read_raw_fif(data_path, preload=False)\n",
    "\n",
    "                # Splitting full EEG recording into 5 second slices\n",
    "                num_intervals = (full_data.get_data().shape[1] // 3) // (84 * 5)\n",
    "                for i in range(num_intervals):\n",
    "                    slice = [data_path, i*84, i*84+84]\n",
    "                    \n",
    "                    target, tag_string = self.get_target(row)\n",
    "\n",
    "                    self.data_dict[id] = slice\n",
    "\n",
    "                    eeg_label_dict[id] = target\n",
    "                    self.class_counts[tag_string] += 1\n",
    "                    id += 1\n",
    "\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        progress_bar.close()\n",
    "\n",
    "        self.items = list(eeg_label_dict.items())\n",
    "        print('Class counts: ', self.class_counts)\n",
    "\n",
    "    def get_class_counts(self):\n",
    "        enum_class_count = {}\n",
    "        i = 0\n",
    "        for _, count in self.class_counts.items():\n",
    "            enum_class_count[i] = count\n",
    "            i += 1\n",
    "        return enum_class_count\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        return self.items[idx][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.items[idx][1]\n",
    "        eeg_index = self.data_dict[self.items[idx][0]]\n",
    "\n",
    "        full_data = mne.io.read_raw_fif(eeg_index[0], preload=False)\n",
    "        # Define frequencies of interest (log-spaced)\n",
    "        frequencies = np.logspace(np.log10(1), np.log10(40), num=40)\n",
    "        n_cycles = frequencies / 2.  # Different number of cycle per frequency\n",
    "        # Compute time-frequency representation with Morlet wavelets\n",
    "        power = tfr_morlet(full_data, freqs=frequencies, n_cycles=n_cycles, use_fft=True, return_itc=False, decim=3, n_jobs=1)\n",
    "        # power has shape (129, 40, 11609)\n",
    "\n",
    "        eeg_data = power.get_data()[:, :, eeg_index[1] : eeg_index[2]]\n",
    "\n",
    "        if self.transform:\n",
    "            eeg_data = self.transform(eeg_data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        new_shape = (eeg_data.shape[0], eeg_data.shape[1] * eeg_data.shape[2])  # (129, 40*84)\n",
    "        eeg_data = eeg_data.reshape(new_shape)\n",
    "\n",
    "        return eeg_data, label\n",
    "        # eeg_data has shape (129, 3360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SpectrogramCNN, self).__init__()\n",
    "        # Reduce the number of convolutional layers and channels\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 10), padding=(1, 5))  # One layer, more channels\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d((2, 4))  # Pooling to reduce dimensions\n",
    "\n",
    "        # Simplified dropout and fewer fully connected layers\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        # The fully connected layer sizes need to be adjusted based on the actual output dimensions\n",
    "        # Placeholder dimensions for illustration; you will need to calculate the exact number based on your input size after pooling\n",
    "        self.fc1 = nn.Linear(1733760, num_classes)  # Direct connection to output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop for CNN & spectrogram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup datasets and loaders\n",
    "dsets = {\n",
    "    'train': SpectroDataset(train_dir, train_behav_file, data_transforms['train']),\n",
    "    'val': SpectroDataset(val_dir, val_behav_file, data_transforms['val'])\n",
    "}\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    targets = np.array([dsets[split].get_label(i) for i in range(len(dsets[split]))])\n",
    "    class_counts = dsets[split].get_class_counts()\n",
    "    class_weights = np.array([1.0 / class_counts[label] if class_counts[label] > 0 else 0 for label in targets])\n",
    "    sampler = WeightedRandomSampler(class_weights, num_samples=len(class_weights), replacement=True)\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=b_size, num_workers=0, sampler=sampler)\n",
    "    print('done making loader:', split)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model_ft = SpectrogramCNN(num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "# Device configuration with MPS support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model_ft.to(device)\n",
    "criterion.to(device)\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Train model\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dset_loaders, dset_sizes, num_epochs=n_epochs)\n",
    "\n",
    "# Output results\n",
    "for split in ['train', 'val']:\n",
    "    print(split, 'accuracies by epoch:', accuracies[split])\n",
    "    print(split, 'losses by epoch:', losses[split])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGMLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=4):\n",
    "        super(EEGMLP, self).__init__()\n",
    "        # Input size should match the total number of data points in each EEG sample\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(512, 256)         # Second hidden layer\n",
    "        self.fc3 = nn.Linear(256, 128)         # Third hidden layer\n",
    "        self.fc4 = nn.Linear(128, num_classes) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Forward pass through the network\n",
    "        x = F.relu(self.fc1(x))  # Activation function for first layer\n",
    "        x = F.relu(self.fc2(x))  # Activation function for second layer\n",
    "        x = F.relu(self.fc3(x))  # Activation function for third layer\n",
    "        x = self.fc4(x)          # No activation function for output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/192 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:08<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:  {'HEHF': 2489, 'HELF': 238, 'LEHF': 1371, 'LELF': 878}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:02<00:00, 23.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:  {'HEHF': 508, 'HELF': 101, 'LEHF': 535, 'LELF': 100}\n",
      "done making loader: train\n",
      "done making loader: val\n",
      "Training on mps\n",
      "Training on: mps\n",
      "----------\n",
      "Epoch 0/9\n",
      "----------\n",
      "LR is set to 0.0001\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 300\n"
     ]
    }
   ],
   "source": [
    "# Setup datasets and loaders\n",
    "dsets = {\n",
    "    'train': RawDataset(train_dir, train_behav_file, data_transforms['train']),\n",
    "    'val': RawDataset(val_dir, val_behav_file, data_transforms['val'])\n",
    "}\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    targets = np.array([dsets[split].get_label(i) for i in range(len(dsets[split]))])\n",
    "    class_counts = dsets[split].get_class_counts()\n",
    "    class_weights = np.array([1.0 / class_counts[label] if class_counts[label] > 0 else 0 for label in targets])\n",
    "    sampler = WeightedRandomSampler(class_weights, num_samples=len(class_weights), replacement=True)\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=b_size, num_workers=0, sampler=sampler)\n",
    "    print('done making loader:', split)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model_ft = EEGMLP(input_size=129*1250, num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "# Device configuration with MPS support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model_ft.to(device)\n",
    "criterion.to(device)\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Train model\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dset_loaders, dset_sizes, num_epochs=n_epochs)\n",
    "\n",
    "# Output results\n",
    "for split in ['train', 'val']:\n",
    "    print(split, 'accuracies by epoch:', accuracies[split])\n",
    "    print(split, 'losses by epoch:', losses[split])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectroMLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=4):\n",
    "        super(SpectroMLP, self).__init__()\n",
    "        # Input size should match the total number of data points in each EEG sample\n",
    "        self.fc1 = nn.Linear(input_size, 1024)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(1024, 512)         # Second hidden layer\n",
    "        self.fc3 = nn.Linear(512, 256)          # Third hidden layer\n",
    "        self.fc4 = nn.Linear(256, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Forward pass through the network\n",
    "        x = F.relu(self.fc1(x))  # Activation function for first layer\n",
    "        x = F.relu(self.fc2(x))  # Activation function for second layer\n",
    "        x = F.relu(self.fc3(x))  # Activation function for third layer\n",
    "        x = self.fc4(x)          # No activation function for output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup datasets and loaders\n",
    "dsets = {\n",
    "    'train': SpectroDataset(train_dir, train_behav_file, data_transforms['train']),\n",
    "    'val': SpectroDataset(val_dir, val_behav_file, data_transforms['val'])\n",
    "}\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    targets = np.array([dsets[split].get_label(i) for i in range(len(dsets[split]))])\n",
    "    class_counts = dsets[split].get_class_counts()\n",
    "    class_weights = np.array([1.0 / class_counts[label] if class_counts[label] > 0 else 0 for label in targets])\n",
    "    sampler = WeightedRandomSampler(class_weights, num_samples=len(class_weights), replacement=True)\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=b_size, num_workers=0, sampler=sampler)\n",
    "    print('done making loader:', split)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model_ft = SpectroMLP(input_size=129*1250, num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "# Device configuration with MPS support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model_ft.to(device)\n",
    "criterion.to(device)\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Train model\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dset_loaders, dset_sizes, num_epochs=n_epochs)\n",
    "\n",
    "# Output results\n",
    "for split in ['train', 'val']:\n",
    "    print(split, 'accuracies by epoch:', accuracies[split])\n",
    "    print(split, 'losses by epoch:', losses[split])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
