{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from modules.spec_dataset import *\n",
    "from modules.train_prep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class SpectroMLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=4):\n",
    "        super(SpectroMLP, self).__init__()\n",
    "        # Two hidden layers with a moderate number of neurons\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(512, 256)         # Second hidden layer\n",
    "        self.fc3 = nn.Linear(256, num_classes) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor if not already flattened\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Forward pass through the network\n",
    "        x = F.relu(self.fc1(x))  # Activation function for the first hidden layer\n",
    "        x = F.relu(self.fc2(x))  # Activation function for the second hidden layer\n",
    "        x = self.fc3(x)          # No activation function for output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:06<00:00, 27.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:  {'HEHF': 2482, 'HELF': 238, 'LEHF': 1366, 'LELF': 874}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:01<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:  {'HEHF': 507, 'HELF': 100, 'LEHF': 533, 'LELF': 100}\n",
      "done making loader: train\n",
      "done making loader: val\n",
      "Training on mps\n",
      "----------\n",
      "Epoch 0/9\n",
      "----------\n",
      "LR is set to 0.0001\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "elif torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Setup datasets and loaders\n",
    "dsets = {\n",
    "    'train': SpectroDataset(train_dir, train_behav_file, data_transforms['train']),\n",
    "    'val': SpectroDataset(val_dir, val_behav_file, data_transforms['val'])\n",
    "}\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    targets = np.array([dsets[split].get_label(i) for i in range(len(dsets[split]))])\n",
    "    class_counts = dsets[split].get_class_counts()\n",
    "    class_weights = np.array([1.0 / class_counts[label] if class_counts[label] > 0 else 0 for label in targets])\n",
    "    sampler = WeightedRandomSampler(class_weights, num_samples=len(class_weights), replacement=True)\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=b_size, num_workers=0, sampler=sampler)\n",
    "    print('done making loader:', split)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model_ft = SpectroMLP(input_size=108360, num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "# Device configuration with MPS support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model_ft.to(device)\n",
    "criterion.to(device)\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Train model\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dset_loaders, dset_sizes, num_epochs=n_epochs)\n",
    "\n",
    "# Output results\n",
    "for split in ['train', 'val']:\n",
    "    print(split, 'accuracies by epoch:', accuracies[split])\n",
    "    print(split, 'losses by epoch:', losses[split])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
